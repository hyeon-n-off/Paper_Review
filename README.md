### Paper_Review
[Paper Reivew] 논문을 읽고 정리 및 실습해보자.


* Attention Is All You Need (NIPS 2017)
  * [Original Paper Link](https://arxiv.org/abs/1706.03762) / [Summary PDF](https://github.com/hyeon-n-off/Paper_Review/blob/main/%5BTransformer%5D%20Attention%20Is%20All%20You%20Need/Transformer%20%EB%85%BC%EB%AC%B8%20%EB%A6%AC%EB%B7%B0.pdf) / [Code Practice](https://github.com/hyeon-n-off/Paper_Review/blob/main/%5BTransformer%5D%20Attention%20Is%20All%20You%20Need/Transformer%20%EC%8B%A4%EC%8A%B5.ipynb)

* Low Rank Adaptation of Large Language Models (2021)
  * [Original Paper Link](https://arxiv.org/pdf/2106.09685) / [Summary PDF](https://github.com/hyeon-n-off/Paper_Review/blob/main/%5BLoRA%5D%20Low%20Rank%20Adaptation%20of%20Large%20Language%20Models/LoRA%20%EB%85%BC%EB%AC%B8%20%EB%A6%AC%EB%B7%B0.pdf) / [Code Practice](https://github.com/hyeon-n-off/Paper_Review/blob/main/%5BLoRA%5D%20Low%20Rank%20Adaptation%20of%20Large%20Language%20Models/LoRA%20%EC%8B%A4%EC%8A%B5.ipynb)
