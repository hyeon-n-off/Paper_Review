{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 라이브러리 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig, TaskType, get_peft_model\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "import time\n",
    "import psutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 기본 모델 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"bert-base-uncased\"\n",
    "model_original = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. LoRA 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 148,994 || all params: 109,632,772 || trainable%: 0.1359\n"
     ]
    }
   ],
   "source": [
    "# 자세한 매개변수 설명은 아래 링크 참조\n",
    "# https://huggingface.co/docs/peft/v0.14.0/en/package_reference/lora#peft.LoraConfig \n",
    "# https://huggingface.co/docs/peft/package_reference/peft_types\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=4,\n",
    "    # Transformer architecture에서 query, key, value, output 행렬 중 어떤 행렬에 대해서 LoRA를 적용할 것인지 선택\n",
    "    target_modules=[\"query\", \"value\"],\n",
    "    task_type=TaskType.SEQ_CLS,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05\n",
    ")\n",
    "\n",
    "model_lora = get_peft_model(model=model_original, peft_config=lora_config)\n",
    "\n",
    "model_lora.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. 데이터셋 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f82b5a1334248ac9d64360fde7a0731",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 텍스트 분류 (Text Classification)\n",
    "# IMDb: 영화 리뷰 감성 분석 (긍정 / 부정)\n",
    "dataset = load_dataset(\"imdb\")\n",
    "\n",
    "\n",
    "# 데이터 전처리 함수\n",
    "def preprocess_function(tokenizer, data):\n",
    "    return tokenizer(data[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "# 100개만 사용\n",
    "train_dataset = dataset[\"train\"].select(range(100)).map(\n",
    "    lambda data: preprocess_function(tokenizer, data), batched=True)\n",
    "\n",
    "eval_dataset = dataset[\"test\"].select(range(100)).map(\n",
    "    lambda data: preprocess_function(tokenizer, data), batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_memory_usage():\n",
    "    process = psutil.Process()\n",
    "    memory_info = process.memory_info()\n",
    "    \n",
    "    return memory_info.rss / (1024 ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MSI\\AppData\\Local\\Temp\\ipykernel_16604\\1202334515.py:19: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer_base = Trainer(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d90bd2c5ffc04cd496fff29d1d46e725",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ba2bfe1459c4f9da71e7dcfa5efa325",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.03844061121344566, 'eval_runtime': 11.9034, 'eval_samples_per_second': 8.401, 'eval_steps_per_second': 0.336, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04d8586c173142f990453914340f39e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.008409840054810047, 'eval_runtime': 10.2117, 'eval_samples_per_second': 9.793, 'eval_steps_per_second': 0.392, 'epoch': 2.0}\n",
      "{'train_runtime': 140.3825, 'train_samples_per_second': 1.425, 'train_steps_per_second': 0.057, 'train_loss': 0.12301313132047653, 'epoch': 2.0}\n",
      "Base Model Training Time: 141.12345552444458 seconds\n",
      "Base Model Memory Usage: 846.1328125 MB\n"
     ]
    }
   ],
   "source": [
    "# 1. 기본 모델 bert-base-uncased\n",
    "start_time_base = time.time()\n",
    "start_memory_base = get_memory_usage()\n",
    "\n",
    "training_args_base = TrainingArguments(\n",
    "    output_dir=\"./results/base\",\n",
    "    learning_rate=1e-3,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs/base\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    seed=2024,\n",
    ")\n",
    "\n",
    "trainer_base = Trainer(\n",
    "    model=model_original,\n",
    "    args=training_args_base,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "trainer_base.train()\n",
    "\n",
    "end_time_base = time.time()\n",
    "time_base = end_time_base - start_time_base\n",
    "\n",
    "end_memory_base = get_memory_usage()\n",
    "memory_base = end_memory_base - start_memory_base\n",
    "\n",
    "print(f\"Base Model Training Time: {time_base} seconds\")\n",
    "print(f\"Base Model Memory Usage: {memory_base} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MSI\\AppData\\Local\\Temp\\ipykernel_16604\\3085779995.py:19: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer_lora = Trainer(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23783b1489334ec8a6307cdba8b57944",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a3b1c891ec0490b90090ac313591263",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.00016954993770923465, 'eval_runtime': 80.9768, 'eval_samples_per_second': 1.235, 'eval_steps_per_second': 0.049, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc1c29f8ddb24df6b3b8df000787943f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 7.135372288757935e-05, 'eval_runtime': 58.8425, 'eval_samples_per_second': 1.699, 'eval_steps_per_second': 0.068, 'epoch': 2.0}\n",
      "{'train_runtime': 258.0062, 'train_samples_per_second': 0.775, 'train_steps_per_second': 0.031, 'train_loss': 0.001580627984367311, 'epoch': 2.0}\n",
      "LoRA Model Training Time: 258.6091229915619 seconds\n",
      "LoRA Model Memory Usage: -64.5390625 MB\n"
     ]
    }
   ],
   "source": [
    "# 2. LoRA 적용 모델\n",
    "start_time_lora = time.time()\n",
    "start_memory_lora = get_memory_usage()\n",
    "\n",
    "training_args_lora = TrainingArguments(\n",
    "    output_dir=\"./results/LoRA\",\n",
    "    learning_rate=1e-3,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs/LoRA\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    seed=2024,\n",
    ")\n",
    "\n",
    "trainer_lora = Trainer(\n",
    "    model=model_lora,\n",
    "    args=training_args_lora,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "trainer_lora.train()\n",
    "\n",
    "end_time_lora = time.time()\n",
    "time_lora = end_time_lora - start_time_lora\n",
    "\n",
    "end_memory_lora = get_memory_usage()\n",
    "memory_lora = end_memory_lora - start_memory_lora\n",
    "\n",
    "print(f\"LoRA Model Training Time: {time_lora} seconds\")\n",
    "print(f\"LoRA Model Memory Usage: {memory_lora} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. 성능 비교하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5d1ab6210414651bde6dab18c8ed14d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bdc69e3a3b84d318196732eae4a0e5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "기본 모델 성능:\n",
      "{'eval_loss': 7.135372288757935e-05, 'eval_runtime': 58.2201, 'eval_samples_per_second': 1.718, 'eval_steps_per_second': 0.069, 'epoch': 2.0}\n",
      "LoRA 모델 성능:\n",
      "{'eval_loss': 7.135372288757935e-05, 'eval_runtime': 66.7357, 'eval_samples_per_second': 1.498, 'eval_steps_per_second': 0.06, 'epoch': 2.0}\n"
     ]
    }
   ],
   "source": [
    "results_base = trainer_base.evaluate()\n",
    "results_lora = trainer_lora.evaluate()\n",
    "\n",
    "print(\"기본 모델 성능:\")\n",
    "print(results_base)\n",
    "\n",
    "print(\"LoRA 모델 성능:\")\n",
    "print(results_lora)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
